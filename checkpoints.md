# Основные этапы для достижения цели

1) Сбор известных данных от токсичности химических соединений (до 15.10.2024)
2) Генерация физико-химических дескрипторов и EDA по ним (до 05.11.2024)
3) Построение первых ML моделей (до 20.11.2024)
4) Сервис над бейзлайном (до 10.12.2024)
5) Дополнительная генерация признаков и улучшение текущих моделей (до 01.04.2025)
6) Эксперименты с DL (до 15.05.2025)

## Сбор данных
Сбор данных будет осуществляться по 30 основным источникам:

<details>
  <summary>Список источников</summary>
  
1. PubChem 
2. ChemSpider
3. ChemBL 
4. CompTox Chemicals Dashboard
5. COMPTOX
6. TOXRIC  
7. Open Food Tox
8. OpenTox 
9. Acute Toxicity Test Database Query
10. Exploring ToxCost Data
11. TOX 21
12. Comparative Toxicogenomics Database (CTD)
13. ECOTOX 
14. European Chemicals Agency (ECHA)  
15. EMBL-EBI (European Bioinformatics Institute) 
16. Chemical Effects in Biological Systems (CEBS)  
17. UK Chemical Hazards Compendum 
18. Pharmaceuticals in the Environment, Information for Assessing Risk website 
19. Human Metabolome Database (HMDB) 
20. PA Integrated Risk Information System (IRIS)
21. NORMAN Suspect List Exchange
22. SIDER 
23. The Carcinogenic Potency Database
24. Chemical Carcinogenesis Research Information System 
25. Life Science Database Archive
26. TOXICO DB
27. KEGG: Kyoto Encyclopedia of Genes and Genomes
28. RepDose
29. Публикация описывающая построение CATMoS: Collaborative Acute Toxicity Modeling Suite 
30. Публикация об анализе баз данных по токсичности

</details>

Каждый источник будет проработан на предмет "полезности" - то есть сколько в нём данных и как легко их достать. Качественно-количественное описание источников будет [тут](https://docs.google.com/spreadsheets/d/1R5E_jR72js-ya6yBi1ozjt458giZ-A_6EqPiU1vfdLg/edit?gid=0#gid=0)
Итоговый датасет будет сформирован на базе доступной информации из этих источников. 

Для того чтобы дальше было удобно работать с данными, нужно привести собранные в единую структуру.
Для этого потребуется:
- все индификаторы перевести в Smiles
- определеть на каком животном производились замеры
- способ введения вещества
- в рамках одной метрики привести все значения к одним единицам измерения

Итоговый формат данных будет иметь следующую структуру:
|Поле|Описание|
|---|---|
|Smiles|Смайлс химического вещества|
|the experimental animal|подопытное животное|
|the input method|метод введения вещества|
|metric_1|найденная метрика №1|
|metric_2|найденная метрика №2|
|...|...|
|metric_N|найденная метрика №N|


## Генерация признаков

Способов описания химических молекул очень много, но изначально мы рассмотрим 6 основных доменов признаков:
- RDKit2D (физико-химические дискрипторы)
- MACCS
- MorganFingerprints
- Mol2Vec
- Graph2Vec
- RoBERTa

Первые 3 стандарт индустрии и реализованы в библиотеке RDKIT. Вторые 3  - это нейросетевые подходы для генерации эмбедингов описания структуры молекулы.

В первых итерациях будем пользваться первым доменом признаков (RDKit2D) так как:
- они прямо интерпритируемы
- их не так много (порядка 200), что лешит нас проклятия размерности
- они относительно легко считаются из коробки

По мере накопления и улучшения знаний о наших данных мы будем утяжелять модели добавлением новых доменов признаков

Итоговый датасет будет сформирован на базе доступной информации из этих источников. 

Для того чтобы дальше было удобно работать с данными, нужно привести собранные в единую структуру.
Для этого потребуется:
- все индификаторы перевести в Smiles
- определеть на каком животном производились замеры
- способ введения вещества
- в рамках одной метрики привести все значения к одним единицам измерения

Итоговый формат данных будет иметь следующую структуру:
|Поле|Описание|
|---|---|
|Smiles|Смайлс химического вещества|
|the experimental animal|подопытное животное|
|method of administration|метод введения вещества|
|metric_1|найденная метрика №1|
|metric_2|найденная метрика №2|
|...|...|
|metric_N|найденная метрика №N|


## Результаты для Checkpoint 2

### Сбор данных
Собраны данные из 5 источников:
- PubChem
- ChemBL
- TOXRIC 
- CompTox 
- Toxval 

Способы сбора данных различны - от скачивания готовых наборов, до рабтоы с API источника для выборки интересующих объектов с последующим парсингом.

Остальные источники признаны неперспективными в виду малого объема, пересечения и неудобства забора данных.

Исходные датасеты сохранены в [объектном хранилище](https://console.yandex.cloud/folders/b1g1dqndjm3242cgelih/storage/buckets/hse-ai24-team-22-data?key=team-22%2Fdata%2F).

Проведены предварительные EDA для изучения и очистки имеющихся признаков.

### Объединение данных
Сформирован объединенный датасет.


### Генерация дополнительных признаков
Для расширения набора признаков будут использованы т.н. "дескрипторы молекул" - общепринятый в химии способ описания физико-химических свойств молекул.

Для генерации признаков используется библиотека [RDKit](https://rdkit.org/docs/index.html)

Написаны генераторы для:
- MACCS 
- MorganFingerprints 
- 2D-дескрипторы 

Проведение ручного EDA по сгенерированным признакам не представляется рациональным на данном этапе, т.к. их много (более 2000). На следующих этапах будем изучать метрики влияния признаков на таргет и качество моделей.


## Результаты для Checkpoint 3

Создать модель линейной регрессии для предсказания значения LD50.
В качестве исходного датасета принять https://console.yandex.cloud/folders/b1g1dqndjm3242cgelih/storage/buckets/hse-ai24-team-22-data?key=team-86%2Fdata%2Fresultwithfeatures.csv
Целевая переменная - LD50.
Основные этапы
1. Подготовка датасета к работе
   - Удаление сильных выбросов
   - Прологарифмирован таргет
   - Масштабированы числовые признаки с помощью MinMaxScaler(StandardScaler) + закодированы категориальные признаки при помощи One-hot-encoding
   - Проведена фильтрация наиболее ценных признаков для модели различными методами
2. Обучение линейной регрессии
   - Отобраны признаки в соответствии с их значимостью для модели линейной регрессии с использованием метода разделения по фолдам и функций f-regression/selectKBEST/PCA/SVD по отобранным признакам проведено обучение моделей (LinearRegression, Lasso, Ridge). В качестве метрики качества определено использование MAPE (приоритет) и r2.


#### Как можно было заметить, полученные результаты обучения всё ещё имеют плохую предсказательную способов и потребуются более сложные модели в дальнейшем обучении.
